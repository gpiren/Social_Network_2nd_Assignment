---
title: "Social Network - Assignment #2"
author: "Ekin Kızıldaş - Gür Piren"
format: html
toc: true
number-sections: true
toc-depth: 3
date: "2025-05-14"
editor_options:
  markdown:
    wrap: sentence
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  

## Libraries
  
```{r}
#| message: false
#| warning: false
library(tidyverse)
library(igraph)
library(stringr)
library(archive)
library(ggraph) 
library(tidygraph)
library(ggrepel)
library(extrafont)
library(tibble)
library(fmsb)
library(GGally)
library(tidyr)
library(caret)
library(pROC)

```

## Tasks

### Choose a network

Marvel Universe social network, 2002. The network shows Marvel characters as being linked if they jointly appear in the same Marvel comic book.

The dataset can be accessed through this [link](https://networks.skewed.de/net/marvel_universe)

Number of nodes: 19.428
Number of edges: 95.497


### Import network data

One important thing to note about our network is that it is a bipartite network. We have discovered this after consulting the professor, and found out that the first 6.486 rows represent the character nodes while the rest shows the comic books in which characters appear.

We will address the issue using bipartite projection, which will help us separate the characters nodes from the comic book nodes, eventually providing us with the robust results when assessing different types of similarity metrics. To not spoil all the fun just yet, let's move onto data cleaning part.



```{r}
marvel_nodes <- read.csv("data/nodes.csv", stringsAsFactors = FALSE,
                         quote = "\"", fill = TRUE)

marvel_links <- read.csv("data/edges.csv", stringsAsFactors = FALSE)
```


Data cleaning for the node coordinates

```{r}
# to get proper x and y coordinates

marvel_nodes$x_cor <- as.numeric(str_extract(marvel_nodes$X_pos,
                                             "-?\\d+\\.\\d+"))
marvel_nodes$y_cor <- as.numeric(str_extract_all(marvel_nodes$X_pos,
                                                 "-?\\d+\\.\\d+") %>% 
                                   sapply(`[`, 2))

# we don't need the X_pos anymore
marvel_nodes$X_pos <- NULL
```


Renaming the columns and starting the index column from 1.


```{r}
marvel_nodes <- marvel_nodes |> 
  rename(id = X..index,
         character_name = name) |> 
  mutate(id = id + 1) # for best indexing practice
```

Cleaning the names in the character name column

```{r}
marvel_nodes <- marvel_nodes |> 
  mutate(character_name = str_replace_all(character_name, "/", " ")) |> 
  mutate(character_name = str_trim(str_replace(character_name, "^(\\w+),\\s*([\\w\\s]+)$", "\\2 \\1"))) |> 
  mutate(character_name = str_replace_all(character_name, "[^[:alnum:]\\s]", ""))
```


Applying the same indexing logic to 'marvel_links' where character co-appearances are stored.

```{r}
marvel_links <- marvel_links |> 
  rename(source = X..source,
         target = target)

marvel_links <- marvel_links |> 
  mutate(source = source + 1,
         target = target + 1)
```


This code builds a bipartite graph from marvel_links, keeping only edges between characters and comic books. (The first 6.486 rows belong to characters, whereas the rest is comic books)

We then create the bipartite graph and tag nodes as character (FALSE) or comic book (TRUE).

Lastly, we project the bipartite graph into a character–character network, where two characters are connected if they appear in the same comic book.

```{r}

# only keep proper bipartite edges: one from each type

marvel_links_bip <- marvel_links %>%
  filter((source <= 6486 & target > 6486) | (source > 6486 & target <= 6486))

# recreating the graph with only valid bipartite edges
bipartite_graph <- graph_from_data_frame(marvel_links_bip, vertices = marvel_nodes, directed = FALSE)

# tagging the nodes
V(bipartite_graph)$type <- seq_along(V(bipartite_graph)) > 6486

# character-character network
projections <- bipartite_projection(bipartite_graph)
network_graph <- projections$proj1  

```


**Visualization**

Visualising the network after projection.

The network shows a densely connected core surrounded by many weakly connected nodes, suggesting a small group of central characters who frequently co-appear, while many others have limited connections. The scattered periphery and disconnected components imply minor characters, and the layout highlights the strong centralization.


```{r}
layout <- layout_with_fr(network_graph) 

plot(network_graph, 
     vertex.label = NA, 
     vertex.size = 2, 
     vertex.color = "red", 
     edge.color = "black", 
     edge.width = 0.5, 
     layout = layout)

```


## Link Prediction Project
  

### Delete a fraction of real edges: Randomly remove 10-20% of edges using delete_edges() in igraph. Create a table of deleted (positive) and non-existing (negative) links with sample() for negative class.
  
  
The below code visualizes the process of preparing data for link prediction on the Marvel network in three steps: first, it plots the original network with all connections; then, it removes 15% of the edges, highlights them in gray, and plots this modified network; finally, it creates a reduced network by deleting those edges, generates a negative class of non-existing links, and plots the reduced network. The positive class consists of the removed edges, while the negative class includes an equal number of randomly sampled non-existing node pairs. The plots use node positions from x_cor and y_cor, with red nodes, black edges, and no labels for clarity.

**Original Network:** The full Marvel character-character projection network created from the bipartite character-comic network, showing all connections between characters based on shared comic appearances. 

**Network with Removed Edges:** The same network but with 10–20% of its edges highlighted in gray to indicate which links have been selected for removal. This helps visualize which character relationships are targeted for deletion while still preserving the original structure. (However, due to high volyme of nodes, the gray ones are not very visible)

**Reduced Network:** The resulting network after actually deleting the selected edges. It displays only the remaining connections among characters, making it sparser and visually showing the impact of the edge removal.


```{r}
set.seed(123)

# to ensure the 1x3 layout of three networks - original, network with removed edges, and reduced network
par(mar = c(0, 0, 0, 0), mfrow = c(1, 3))

# original network
plot(network_graph,
     vertex.label = NA,
     vertex.size = 2,
     vertex.color = "red",
     edge.color = "black",
     edge.width = 0.5,
     layout = layout)

# randomly removing 10-20% of edges

remove_frac <- runif(1, 0.10, 0.20)
remove_edges <- sample(1:ecount(network_graph), size = round(remove_frac * ecount(network_graph)))
edges <- as_data_frame(network_graph, what = "edges")
positive_class <- edges[remove_edges, c("from", "to")]

# coloring the removed edges gray for visualization

E(network_graph)$color <- "black"
E(network_graph)$color[remove_edges] <- "gray"

# second plot, the network with removed edges
plot(network_graph,
     vertex.label = NA,
     vertex.size = 2,
     vertex.color = "red",
     edge.width = 0.5,
     layout = layout)

# removing edges to form the reduced graph 
graph_reduced <- delete_edges(network_graph, remove_edges)

# saampling negative class (non-edges)
sample_non_edges <- function(gr, n) {
  non_edges <- data.frame(from = integer(), to = integer())
  while (nrow(non_edges) < n) {
    v1 <- sample(vcount(gr), 1)
    v2 <- sample(vcount(gr), 1)
    if (v1 != v2 && !are_adjacent(gr, v1, v2)) {
      non_edges <- rbind(non_edges, data.frame(from = V(gr)$name[v1], to = V(gr)$name[v2]))
    }
  }
  non_edges
}
negative_class <- sample_non_edges(graph_reduced, nrow(positive_class))

# third plot, the reduced graph (after deletion)
E(graph_reduced)$color <- "black"
plot(graph_reduced,
     vertex.label = NA,
     vertex.size = 2,
     vertex.color = "red",
     edge.width = 0.5,
     layout = layout)


```




### Generate proximity/similarity metrics: Compute heuristics (common neighbors, Jaccard, Adamic-Adar) for all links using similarity() functions in igraph or custom calculations.

**Common Neighbours** 
  
The common neighbours method counts the number of shared neighbors between two nodes, indicating similarity through mutual connections.

In our approach, we used 'Dice' similarity to calculate common neighbors, adjusting it by incorporating the **degree** of the nodes. This method, we believe, will help us weight common neighbors based on node connectivity, offering a more balanced measure that accounts for node importance. We wanted to provide a more balanced view by accounting for the relative importance of nodes by doing this.

After ensuring that the node identifiers in both the positive and negative link sets are stored as integers, we calculate three node similarity matrices (Dice, Jaccard, and Adamic-Adar) for all node pairs in the reduced graph. 

We calculate common neighbors after applying Dice similarity to incorporate both the shared neighbors and the degree of the nodes. This allows us to weight common neighbors more effectively, ensuring that more connected nodes have a proportional influence, which enhances the accuracy of our link prediction. Let's hope it was a good choice!

These similarities are used to assess how likely two unconnected nodes might form a link. After that, the positive and negative examples are combined into a single dataset with a class label indicating whether a pair is a real (1) or fake (0) link. 

Finally, a custom similarity score based on common neighbors is computed using the Dice similarity and the average degree of the two nodes. Then we will move onto other similarity metrics such as Jaccard and Adamic-Adar in the next chunks.


```{r}
# making sure our positive/negative classes are integers
positive_class <- positive_class %>%
  mutate(from = as.integer(from),
         to   = as.integer(to))

negative_class <- negative_class %>%
  mutate(from = as.integer(from),
         to   = as.integer(to))


# precomputing ALL three similarity matrices on the reduced graph

dice_mat    <- similarity(graph_reduced, method = "dice")
jaccard_mat <- similarity(graph_reduced, method = "jaccard")
aa_mat      <- similarity(graph_reduced, method = "invlogweighted")

# combining all
metrics <- bind_rows(
  mutate(positive_class, class = 1),
  mutate(negative_class, class = 0)
)    


# for the common neighbours 
metrics$common_neighbors <- mapply(function(u, v) {
  dice_mat[u, v] * (degree(graph_reduced, u) + degree(graph_reduced, v)) / 2
}, metrics$from, metrics$to)


```

**Jaccard**
  
The Jaccard method measures similarity as the ratio of shared neighbors to total unique neighbors of two nodes, normalizing for network size. Let's calculate that too:

```{r}
metrics$jaccard <- mapply(function(u, v) {
  jaccard_mat[u, v]
}, metrics$from, metrics$to)
```


**Adamic-Adar**
  
The Adamic-Adar method weights shared neighbors by the inverse log of their degrees, emphasizing connections through less-connected nodes. Onto calculating that:

```{r}
metrics$adamic_adar <- mapply(function(u, v) {
  aa_mat[u, v]
}, metrics$from, metrics$to)

```


**For the results**
  
The results from the table indicate pairs of nodes in the Marvel network that share common neighbors but are not directly connected (class = 1).

The common_neighbors column (5 to 70) shows the number of shared neighbors between pairs. These pairs, despite not being connected, have some level of overlap in their network of connections.

The jaccard scores (0.008 to 0.17) represent the ratio of shared neighbors relative to the total number of unique neighbors between the pair. Lower values (like 0.008) suggest minimal overlap in their neighbor relationships, while higher values (such as 0.17) show a more significant overlap of neighbors.

The adamic_adar scores (0.96 to 11.98) indicate the importance of shared neighbors by weighing them based on the inverse logarithm of their degree. Higher scores (11.98) imply that the shared neighbors are less connected overall and are more valuable in predicting a possible connection between the pair.

This variability in the similarity metrics across pairs will be useful for a classifier to determine which pairs are more likely to form direct links in the network, based on their proximity and shared neighbors.

```{r}
head(metrics,10)
```

**Preferential Attachment**
  
'Preferential Attachment' is a metric that predicts if two nodes might connect by multiplying the number of connections (degrees) each node has—a higher number means they’re more likely to connect because nodes with more connections tend to form new ones more easily.


The table shows pairs of nodes in the Marvel network with no direct connection (class = 1), evaluated using the preferential attachment metric.

The pref_attach values (5,940 to 26,625) indicate the likelihood of forming a connection based on node degrees. Higher values (such as 26,625) suggest a greater potential for a link due to higher degrees, while lower values (5,940) indicate a weaker potential.

This metric helps the classifier assess which pairs might form connections based on node connectivity.

```{r}
V(network_graph)$name <- as.character(V(network_graph)) 


metrics$pref_attach <- mapply(function(u, v) {
  u <- as.character(u)
  v <- as.character(v)
  if (u %in% V(network_graph)$name & v %in% V(network_graph)$name) {
    degree(network_graph, v = u) * degree(network_graph, v = v)
  } else {
    0
  }
}, metrics$from, metrics$to)


head(metrics %>% select(-common_neighbors, -jaccard, -adamic_adar))
```


### Modeling Part
  
Next, three classifiers which are logistic regression, a decision tree (CART), and random forest  was trained by using our four heuristics (common neighbors, Jaccard, Adamic–Adar and preferential attachment) as input features. 

All models were evaluated via 5-fold cross-validation in the caret package, optimizing for AUC (ROC) and saving out of fold predictions for comparison.

**Logistic Regression (GLM)** achieved an average ROC of 0.994, with sensitivity around 98% (effectively identifying most true links) but a specificity of 95% (showing a reasonable ability to avoid false positives).

**Decision Tree (rpart)** reached an average ROC of 0.979, with sensitivity around 96% and specificity of 97%, offering a balanced performance with slightly fewer false positives than GLM, while being easier to interpret.

**Random Forest (RF)** scored an average ROC of 0.995, with sensitivity around 97% and specificity of 98%, outperforming both GLM and Decision Tree, thanks to the power of ensemble learning for higher robustness and accuracy.

This comparison shows that logistic regression excels in identifying true connections with high sensitivity, the decision tree offers a clear and interpretable decision-making process with balanced sensitivity and specificity, and random forest delivers the best performance by capturing complex interactions and achieving the highest accuracy across all metrics.

The scatter plot from the second output compares the ROC scores of three models.The Tree model has the lowest ROC score at around 0.980, with a wider confidence interval, indicating more variability. GLM and Random Forest models perform better, with ROC scores around 0.994 and 0.995, respectively, and narrower confidence intervals, suggesting more consistent performance. Overall, GLM and RF outperform the Tree model in terms of predictive accuracy, as indicated by their higher ROC values. (as previously explained)


```{r warning=FALSE}

set.seed(42)

# features & target
X <- metrics %>% dplyr::select(common_neighbors, jaccard, adamic_adar, pref_attach)
y <- factor(metrics$class, levels = c(0,1), labels = c("no","yes"))

# 5-fold cross validation setup, saving probabilities and using ROC for model selection
ctrl <- trainControl(
  method           = "cv",
  number           = 5,
  classProbs       = TRUE,
  summaryFunction  = twoClassSummary,
  savePredictions  = "final"
)

# for logistic regression model
model_glm_lp <- train(
  x         = X,
  y         = y,
  method    = "glm",
  family    = binomial(),
  metric    = "ROC",
  trControl = ctrl
)
# for decision tree 
model_dt <- train(
  x         = X,
  y         = y,
  method    = "rpart",
  metric    = "ROC",
  trControl = ctrl,
  tuneLength = 10
)

# for random forest
model_rf <- train(
  x          = X,
  y          = y,
  method     = "rf",
  metric     = "ROC",
  trControl  = ctrl,
  tuneLength = 5,
  ntree      = 500
)

# for the results
resamps <- resamples(list(
  GLM  = model_glm_lp,
  Tree = model_dt,
  RF   = model_rf
))
print(summary(resamps))
bwplot(resamps, metric = "ROC", main = "ROC Comparison Across Models")

```


### Evaluation of model
  
Logistic Regression achieved an AUC of 0.994, showing strong ranking ability, with high precision (98%) and recall (95%), meaning it accurately identifies most links but still allows some false negatives.

Decision Tree reached an AUC of 0.980, slightly lower but still strong, with balanced precision (96%) and recall (97%), offering interpretable rules and solid overall performance.

Random Forest scored the highest AUC of 0.995 and the best accuracy (97%), with balanced precision (97%) and recall (98%), showing excellent predictive performance by modeling complex patterns in the network.


**Feature importance - and what they suggest**

In the context of a social network, feature importance analysis tells us which network-based features (like number of shared neighbors, Jaccard similarity, Adamic-Adar score, or preferential attachment) are most influential in predicting whether a link (relationship) exists between two nodes (in our case, characters).

In short, feature importance shows which structural patterns in the network are most predictive of connections. So let's move onto the first model:

In the decision tree model, Adamic-adar is the most important feature, meaning it contributed the most to splitting the data and making accurate predictions. Common Neighbors also played a strong role, while Jaccard and Preferential Attachment were less influential. This suggests the tree relies heavily on nuanced shared neighbor information to detect links in the social network.

In the random forest model, Adamic-adar stands out as the most important feature by far, indicating it's the strongest predictor of links in the network. Common neighbors contributes moderately, while Jaccard and especially Preferential Attachmnt play a much smaller role. This shows that the model focuses on deeper structural similarity over basic connection counts.

In the logistic regression model, Adamic-adar and Common neighbours are the most influential features, suggesting they strongly affect the likelihood of a predicted link. Jaccard and Preferential Attachment have much lower importance, indicating they contribute less to the model’s decisions. This reflects a reliance on raw and weighted counts of shared neighbors rather than relative overlap or node popularity.


```{r model-evaluation-and-importance, message=FALSE, warning=FALSE}


# logistic regression
pred_glm <- model_glm_lp$pred
cm_glm   <- confusionMatrix(pred_glm$pred, pred_glm$obs, positive = "yes")
auc_glm  <- roc(pred_glm$obs, pred_glm$yes)$auc

# decision tree
pred_dt <- model_dt$pred
cm_dt   <- confusionMatrix(pred_dt$pred, pred_dt$obs, positive = "yes")
auc_dt  <- roc(pred_dt$obs, pred_dt$yes)$auc

# random forest
pred_rf <- model_rf$pred %>% filter(mtry == model_rf$bestTune$mtry)
cm_rf   <- confusionMatrix(pred_rf$pred, pred_rf$obs, positive = "yes")
auc_rf  <- roc(pred_rf$obs, pred_rf$yes)$auc

# table for model metrics
metrics_new <- tibble(
  Model     = c("Logistic Regression", "Decision Tree", "Random Forest"),
  AUC       = c(auc_glm, auc_dt, auc_rf),
  Accuracy  = c(cm_glm$overall["Accuracy"],
                cm_dt$overall["Accuracy"],
                cm_rf$overall["Accuracy"]),
  Precision = c(cm_glm$byClass["Precision"],
                cm_dt$byClass["Precision"],
                cm_rf$byClass["Precision"]),
  Recall    = c(cm_glm$byClass["Recall"],
                cm_dt$byClass["Recall"],
                cm_rf$byClass["Recall"])
)
print(metrics_new)

#Feature Importance

# decision tree
varImp_dt <- varImp(model_dt, scale = FALSE)
print(varImp_dt)
plot(varImp_dt, main = "Feature Importance - Decision Tree")

# fandom forest
varImp_rf <- varImp(model_rf, scale = FALSE)
print(varImp_rf)
plot(varImp_rf, main = "Feature Importance - Random Forest")


## logistic regression

varImp_lg <- varImp(model_glm_lp, scale = FALSE)
print(varImp_lg)
plot(varImp_lg, main = "Feature Importance - LG")



```

### Potential Improvements

Improving link prediction involves refining the model, data, or features to better capture the patterns that explain how links form in a network. To make this, we can:

**Feature expansion - feature engineering**

Our current features (common neighbors, jaccard, adamic_adar, preferential attachment) used in the assignment are classic heuristics. While effective, they can only capture local structure. We can improve prediction by including more advanced or diverse features, such as:

- Node centrality measures (degree, betweenness, closeness)

- Community detection results (whether the nodes are in the same cluster)

- Temporal or contextual features if available (time of interaction, node type)

- Graph embeddings (Node2Vec, DeepWalk) to capture latent structural info.

**Addressing class imbalance**

If the number of links is much smaller than non-links, this imbalance may bias models we use.

- Downsampling the majority class or upsampling the minority

- Using performance metrics sensitive to imbalance (like AUC, F1)

- Trying cost-sensitive models that penalize false negatives more


**Model tuning and algorithm selection**

Although random forest performed slightly better overall, we could still benefit from some of the following:

- Hyperparameter tuning (more trees, which would adjust the depth)

- Trying other models like XGBoost and LightGBM

- Ensembling models to combine strengths of multiple approaches (We have seen/done this in Advanced Modelling class!)


Lastly, considering the challenges we faced because of the bipartite structure of the network:

**Network-level data quality**

Next time, we might want to check the following before getting hands-on to ensure our network data is well structured

- Are there missing or noisy links?

- Are all nodes relevant?

- Would pruning weak or indirect links help improve the analysis?


## Reference 

R. Alberich, J. Miro-Julia, and F. Rossello, "Marvel Universe looks almost like a real social network." arxiv:cond-mat/0202174 (2002)., http://arxiv.org/abs/cond-mat/0202174
