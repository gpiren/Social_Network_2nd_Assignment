---
  title: "Social Network - Assignment #2"
author: "Ekin Kızıldaş - Gür Piren"
format:
  html:
  toc: true
number-sections: true
toc-depth: 3
date: "2025-05-14"
editor_options: 
  markdown: 
  wrap: sentence
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Link prediction Project

- Choose a network 0f 500 nodes and 5000+ edges
- Import and visualize the network
- Delete a fraction of real edges in the network and create a table
of those links deleted (positive class) and of links non-present
(negative class)
- Generate a number of proximity/similarty metrics heuristics for
each link in the positive and negative class
- Train a binary classifier to predict the links, i.e., to predict the
class (positive/negative) using those heuristics. Use cross-
  validation.
- Evaluate the precision of the model. Which heuristic is the most
important. Why do you think it is the most important?
  - Comment on potential ways to improve the link prediction

**Social Network Analysis Class Roadmap**
  
  **Intro**
  
## Libraries
  
```{r}
#| message: false
#| warning: false
library(tidyverse)
library(igraph)
library(stringr)
library(dplyr)
library(archive)

library(ggraph) 
library(tidygraph)
library(ggrepel)
library(extrafont)
library(tibble)
library(fmsb)
library(GGally)
library(tidyr)
library(caret)
```

## Tasks

### Choose a network

Marvel Universe social network, 2002. The network shows Marvel characters as being linked if they jointly appear in the same Marvel comic book.

The dataset can be accessed through this [link](https://networks.skewed.de/net/marvel_universe)

Number of nodes: 19.428
Number of edges: 95.497


### Import network data

**id:** Unique identifier for each node in the network.

**_pos:** Spatial coordinates (x, y) for node positioning in visualizations.

**name:** Character name associated with each node ("ADAMS, GEORGE").


```{r}
marvel_nodes <- read.csv("data/nodes.csv", stringsAsFactors = FALSE,
                         quote = "\"", fill = TRUE)

marvel_links <- read.csv("data/edges.csv", stringsAsFactors = FALSE)
```


Data cleaning for the node coordinates

```{r}
# to get proper x and y coordinates

marvel_nodes$x_cor <- as.numeric(str_extract(marvel_nodes$X_pos,
                                             "-?\\d+\\.\\d+"))
marvel_nodes$y_cor <- as.numeric(str_extract_all(marvel_nodes$X_pos,
                                                 "-?\\d+\\.\\d+") %>% 
                                   sapply(`[`, 2))

# we don't need the X_pos anymore
marvel_nodes$X_pos <- NULL
```

Renaming the columns and starting the index column from 1 

```{r}
marvel_nodes <- marvel_nodes |> 
  rename(id = X..index,
         character_name = name) |> 
  mutate(id = id + 1) # for best indexing practice
```


```{r}
marvel_nodes <- marvel_nodes |> 
  mutate(character_name = str_replace_all(character_name, "/", " ")) |> 
  mutate(character_name = str_trim(str_replace(character_name, "^(\\w+),\\s*([\\w\\s]+)$", "\\2 \\1"))) |> 
  mutate(character_name = str_replace_all(character_name, "[^[:alnum:]\\s]", ""))
```


Applying the same indexing logic to 'marvel_links' where character co-appearances are stored.

```{r}
marvel_links <- marvel_links |> 
  rename(source = X..source,
         target = target)

marvel_links <- marvel_links |> 
  mutate(source = source + 1,
         target = target + 1)
```


**Visualization**

```{r}
network_graph <- graph_from_data_frame(d = marvel_links, vertices = marvel_nodes, directed = FALSE)

layout <- as.matrix(marvel_nodes[, c("x_cor", "y_cor")])
plot(network_graph, 
     vertex.label = NA, 
     vertex.size = 2, 
     vertex.color = "red", 
     edge.color = "black", 
     edge.width = 0.5, 
     layout = layout)

V(network_graph)$id <- marvel_nodes$id  # explicitly set id attribute

```


**3. Link Prediction Project**
  
### 3.1.
  
**Delete a fraction of real edges: Randomly remove 10-20% of edges using delete_edges() in igraph. Create a table of deleted (positive) and non-existing (negative) links with sample() for negative class.**
  
  
The below code visualizes the process of preparing data for link prediction on the Marvel network in three steps: first, it plots the original network with all connections; then, it removes 15% of the edges, highlights them in gray, and plots this modified network; finally, it creates a reduced network by deleting those edges, generates a negative class of non-existing links, and plots the reduced network. The positive class consists of the removed edges, while the negative class includes an equal number of randomly sampled non-existing node pairs. The plots use node positions from x_cor and y_cor, with red nodes, black edges, and no labels for clarity.



**Original Network:** The full Marvel network (network_graph) with all its nodes and edges as loaded from your data, showing all connections between characters.

**Network with Removed Edges:** The same network_graph but with 15% of its edges marked in gray to indicate which ones will be removed, while still displaying all nodes and edges.

**Reduced Network:** The modified network (graph_reduced) after actually removing those 15% of edges, showing only the remaining connections between nodes.


```{r}
set.seed(123)
par(mar=c(0,0,0,0), mfrow=c(1,3))
layout <- as.matrix(marvel_nodes[, c("x_cor", "y_cor")])
plot(network_graph, vertex.label=NA, vertex.size=2, vertex.color="red", edge.color="black", edge.width=0.5, layout=layout)

# deleting 15% of edges
edges <- as_data_frame(network_graph, what = "edges")
remove_frac <- 0.15
remove_edges <- sample(1:ecount(network_graph), size = round(remove_frac * ecount(network_graph)))
positive_class <- edges[remove_edges, c("from", "to")]
E(network_graph)$color <- "black"
E(network_graph)$color[remove_edges] <- "gray"
plot(network_graph, vertex.label=NA, vertex.size=2, vertex.color="red", edge.width=0.5, layout=layout)

# creating a negative class and plot reduced graph

graph_reduced <- delete_edges(network_graph, remove_edges)
sample_non_edges <- function(gr, n) {
  non_edges <- data.frame(from = integer(), to = integer())
  while (nrow(non_edges) < n) {
    v1 <- sample(vcount(gr), 1)
    v2 <- sample(vcount(gr), 1)
    if (v1 != v2 && !are_adjacent(gr, v1, v2)) {
      non_edges <- rbind(non_edges, data.frame(from = v1, to = v2))
    }
  }
  non_edges
}
negative_class <- sample_non_edges(graph_reduced, nrow(positive_class))
E(graph_reduced)$color <- "black"
plot(graph_reduced, vertex.label=NA, vertex.size=2, vertex.color="red", edge.width=0.5, layout=layout)

```


### 3.2.

Generate proximity/similarity metrics: Compute heuristics (common neighbors, Jaccard, Adamic-Adar) for all links using similarity() functions in igraph or custom calculations.

**Common Neighbours** 
  
The common neighbours method counts the number of shared neighbors between two nodes, indicating similarity through mutual connections.

In Step 2, we compute similarity matrices on the reduced graph to get similarity scores for all pairs of nodes at once, which is faster than calculating them one-by-one for each link in metrics. 

We use the reduced graph because it reflects the network after removing some edges (positive class), mimicking a realworld scenario where we predict missing links based on the remaining structure.


The dice method in similarity calculates the Dice coefficient for all pairs of nodes, which is a similarity score based on shared neighbors. We use it because it’s a quick way to get a value related to common neighbors, which we can then adjust to find the actual count of shared neighbors.

In the fourth step, we calculate common neighbors by "undoing" the Dice normalization, we take the Dice coefficient from dice_mat and multiply it by (degree(u) + degree(v)) / 2 to convert it back to the raw number of shared neighbors.


```{r}
# making sure our positive/negative classes are integers
positive_class <- positive_class %>%
  mutate(from = as.integer(from),
         to   = as.integer(to))

negative_class <- negative_class %>%
  mutate(from = as.integer(from),
         to   = as.integer(to))


# precomputing ALL three similarity matrices on the reduced graph

dice_mat    <- similarity(graph_reduced, method = "dice")
jaccard_mat <- similarity(graph_reduced, method = "jaccard")
aa_mat      <- similarity(graph_reduced, method = "invlogweighted")

# combining all
metrics <- bind_rows(
  mutate(positive_class, class = 1),
  mutate(negative_class, class = 0)
)    


# for the common neighbours 
metrics$common_neighbors <- mapply(function(u, v) {
  dice_mat[u, v] * (degree(graph_reduced, u) + degree(graph_reduced, v)) / 2
}, metrics$from, metrics$to)


```

**Jaccard**
  
The Jaccard method measures similarity as the ratio of shared neighbors to total unique neighbors of two nodes, normalizing for network size. Let's calculate that too:

```{r}
metrics$jaccard <- mapply(function(u, v) {
  jaccard_mat[u, v]
}, metrics$from, metrics$to)
```


**Adamic-Adar**
  
The Adamic-Adar method weights shared neighbors by the inverse log of their degrees, emphasizing connections through less-connected nodes. Onto calculating that:

```{r}
metrics$adamic_adar <- mapply(function(u, v) {
  aa_mat[u, v]
}, metrics$from, metrics$to)

```


**For the results**
  
  The results from metrics highlight pairs of nodes with at least one common neighbor, all in the negative class (class = 0), meaning they are non-existing links in our Marvel network. 

The common_neighbors column (1 to 3) shows these pairs share a few neighbors despite not being directly connected. 
The jaccard scores (0.04 to 0.67) measure the fraction of shared neighbors relative to all unique neighbors of the pair, where higher values (0.67) indicate the pair’s neighbors are very similar, and lower values (0.04) mean they share little overlap compared to their total connections. 

The adamic_adar scores (0.14 to 0.52) weigh shared neighbors by the inverse log of their degrees, giving more importance to neighbors with fewer connections—higher scores (0.52) suggest the shared neighbors are less connected overall, making them more significant for linking the pair. 

The variation in similarity metrics will help later the classifier identify which pairs are more likely to form connections based on their network proximity.


```{r}

nonzero <- which(metrics$common_neighbors > 0)
head(metrics[nonzero, ], 10)

```


**Preferential Attachment**
  
'Preferential Attachment' is a metric that predicts if two nodes might connect by multiplying the number of connections (degrees) each node has—a higher number means they’re more likely to connect because nodes with more connections tend to form new ones more easily.


The output shows pairs of nodes, all in the positive class (class = 1, meaning these are removed edges that originally existed in our Marvel network). The pref_attach values range from 25 to 4494: low values like 25 (row 5) indicate the nodes have few connections (5 * 5 = 25), suggesting lower likelihood of connecting based on popularity; high values like 4494 (row 6) indicate both nodes have many connections (66 * 68 = 4494), suggesting a higher likelihood of connecting due to their prominence in the network.


```{r}
# preferential attachment (product of degrees)
metrics$pref_attach <- mapply(function(u, v) {
  from_idx <- which(V(network_graph)$id == u)
  to_idx <- which(V(network_graph)$id == v)
  if (length(from_idx) == 0 || length(to_idx) == 0) return(0)
  degree(network_graph, from_idx) * degree(network_graph, to_idx)
}, metrics$from, metrics$to)

# Check results for preferential attachment
head(metrics %>% select(-common_neighbors, -jaccard, -adamic_adar))
```


**3.3.**
  
Next, three classifiers which are logistic regression, a decision tree (CART), and random forest  was trained by using our four heuristics (common neighbors, Jaccard, Adamic–Adar and preferential attachment) as input features. All models were evaluated via 5-fold cross-validation in the caret package, optimizing for AUC (ROC) and saving out-of-fold predictions for detailed comparison.

**Logistic Regression** achieved an average AUC of 0.923, with recall near 96% (recovering almost all true links) but a lower specificity of 67% (more false positives).
**Decision Tree (CART)** reached an AUC of 0.909, with recall around 89% and specificity of 81%, offering a simple, interpretable set of rules that balances link detection and false-positive control.

**Random Forest** scored an AUC of 0.892, with recall around 90% and specificity of 80%, leveraging ensemble learning for robustness but slightly trailing the single tree.

This comparison shows that logistic regression excels at ranking and capturing nearly every true connection, the decision tree delivers a clear decision logic with solid balance between sensitivity and specificity, and random forest provides a robust middle ground by modeling feature interactions.

```{r}
library(caret)
set.seed(42)

# 1) Features & target
X <- metrics %>% dplyr::select(common_neighbors, jaccard, adamic_adar, pref_attach)
y <- factor(metrics$class, levels = c(0,1), labels = c("no","yes"))

# 2) 5-fold CV setup: save probabilities and use ROC for model selection
ctrl <- trainControl(
  method           = "cv",
  number           = 5,
  classProbs       = TRUE,
  summaryFunction  = twoClassSummary,
  savePredictions  = "final"
)

# 3) Logistic Regression model
model_glm_lp <- train(
  x         = X,
  y         = y,
  method    = "glm",
  family    = binomial(),
  metric    = "ROC",
  trControl = ctrl
)
# 4) Decision Tree (rpart)
model_dt <- train(
  x         = X,
  y         = y,
  method    = "rpart",
  metric    = "ROC",
  trControl = ctrl,
  tuneLength = 10
)

# 5) Random Forest
model_rf <- train(
  x          = X,
  y          = y,
  method     = "rf",
  metric     = "ROC",
  trControl  = ctrl,
  tuneLength = 5,
  ntree      = 500
)

# 6) Summarize results
resamps <- resamples(list(
  GLM  = model_glm_lp,
  Tree = model_dt,
  RF   = model_rf
))
print(summary(resamps))
bwplot(resamps, metric = "ROC", main = "ROC Comparison Across Models")

```


**3.4.**
  
 To evaluate model performance, accuracy, precision, recall, and AUC were calculated using out-of-fold predictions from cross-validation. Logistic regression achieved the highest AUC (0.923) and precision (0.947), indicating strong ranking performance and few false positives. However, its recall (0.675) was lower, suggesting it missed some true links. The decision tree offered a more balanced performance with solid recall (0.807) and a good AUC (0.911). Random forest had the highest accuracy (0.85) and similar recall (0.805), but slightly lower AUC (0.887).

To understand which heuristics contributed most to predictions, varImp() function was used the on all three models. In every case—logistic regression, decision tree, and random forest—the preferential attachment score was by far the most influential feature. For example, in the logistic model, pref_attach had an importance score over 50, while the next highest features like common_neighbors, adamic_adar, and jaccard scored below 0.01. This pattern repeated in tree-based models, highlighting that nodes with more connections were consistently favored by all algorithms. This aligns with theoretical expectations: in social networks, highly connected nodes tend to attract even more links, making preferential attachment a dominant predictor of future connections.


```{r model-evaluation-and-importance, message=FALSE, warning=FALSE}
library(caret)
library(pROC)
library(dplyr)

#LOGISTIC REGRESSION
pred_glm <- model_glm_lp$pred
cm_glm   <- confusionMatrix(pred_glm$pred, pred_glm$obs, positive = "yes")
auc_glm  <- roc(pred_glm$obs, pred_glm$yes)$auc

# DECISION TREE
pred_dt <- model_dt$pred
cm_dt   <- confusionMatrix(pred_dt$pred, pred_dt$obs, positive = "yes")
auc_dt  <- roc(pred_dt$obs, pred_dt$yes)$auc

# RANDOM FOREST
pred_rf <- model_rf$pred %>% filter(mtry == model_rf$bestTune$mtry)
cm_rf   <- confusionMatrix(pred_rf$pred, pred_rf$obs, positive = "yes")
auc_rf  <- roc(pred_rf$obs, pred_rf$yes)$auc

# METRIC TABLE
metrics_new <- tibble(
  Model     = c("Logistic Regression", "Decision Tree", "Random Forest"),
  AUC       = c(auc_glm, auc_dt, auc_rf),
  Accuracy  = c(cm_glm$overall["Accuracy"],
                cm_dt$overall["Accuracy"],
                cm_rf$overall["Accuracy"]),
  Precision = c(cm_glm$byClass["Precision"],
                cm_dt$byClass["Precision"],
                cm_rf$byClass["Precision"]),
  Recall    = c(cm_glm$byClass["Recall"],
                cm_dt$byClass["Recall"],
                cm_rf$byClass["Recall"])
)
print(metrics_new)

#FEATURE IMPORTANCE

# Decision Tree
varImp_dt <- varImp(model_dt, scale = FALSE)
print(varImp_dt)
plot(varImp_dt, main = "Feature Importance - Decision Tree")

# Random Forest
varImp_rf <- varImp(model_rf, scale = FALSE)
print(varImp_rf)
plot(varImp_rf, main = "Feature Importance - Random Forest")


## LG

varImp_lg <- varImp(model_glm_lp, scale = FALSE)
print(varImp_lg)
plot(varImp_lg, main = "Feature Importance - LG")




```

### 3.5  Potential Improvements

While the current models using structural heuristics performed reasonably well, there is still room for improvement. One direction would be to incorporate node-level attributes such as degree centrality, community membership, or even character metadata (e.g., gender, popularity, or comic genre) to enrich the feature set and provide more contextual signals for link prediction. Additionally, exploring more advanced models like gradient boosting or support vector machines could help capture non-linear relationships between features.

For deeper improvements, graph embedding techniques like node2vec or DeepWalk can be used to generate dense vector representations of nodes that capture both local and global network structure. Finally, using Graph Neural Networks (GNNs)—which learn directly from the graph structure—could allow the model to understand more complex patterns of connectivity that heuristic-based features might miss. These approaches could potentially boost both precision and recall in predicting future or hidden links.





