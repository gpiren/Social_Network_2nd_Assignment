---
  title: "Social Network - Assignment #2"
author: "Ekin Kızıldaş - Gür Piren"
format:
  html:
  toc: true
number-sections: true
toc-depth: 3
date: "2025-05-14"
editor_options: 
  markdown: 
  wrap: sentence
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Link prediction Project

- Choose a network 0f 500 nodes and 5000+ edges
- Import and visualize the network
- Delete a fraction of real edges in the network and create a table
of those links deleted (positive class) and of links non-present
(negative class)
- Generate a number of proximity/similarty metrics heuristics for
each link in the positive and negative class
- Train a binary classifier to predict the links, i.e., to predict the
class (positive/negative) using those heuristics. Use cross-
  validation.
- Evaluate the precision of the model. Which heuristic is the most
important. Why do you think it is the most important?
  - Comment on potential ways to improve the link prediction

**Social Network Analysis Class Roadmap**
  
  **Intro**
  
## Libraries
  
```{r}
#| message: false
#| warning: false
library(tidyverse)
library(igraph)
library(stringr)
library(dplyr)
library(archive)

library(ggraph) 
library(tidygraph)
library(ggrepel)
library(extrafont)
library(tibble)
library(fmsb)
library(GGally)
library(tidyr)
```

## Tasks

### Choose a network

Marvel Universe social network, 2002. The network shows Marvel characters as being linked if they jointly appear in the same Marvel comic book.

The dataset can be accessed through this [link](https://networks.skewed.de/net/marvel_universe)

Number of nodes: 19.428
Number of edges: 95.497


### Import network data

**id:** Unique identifier for each node in the network.

**_pos:** Spatial coordinates (x, y) for node positioning in visualizations.

**name:** Character name associated with each node ("ADAMS, GEORGE").


```{r}
marvel_nodes <- read.csv("data/nodes.csv", stringsAsFactors = FALSE,
                         quote = "\"", fill = TRUE)

marvel_links <- read.csv("data/edges.csv", stringsAsFactors = FALSE)
```


Data cleaning for the node coordinates

```{r}
# to get proper x and y coordinates

marvel_nodes$x_cor <- as.numeric(str_extract(marvel_nodes$X_pos,
                                             "-?\\d+\\.\\d+"))
marvel_nodes$y_cor <- as.numeric(str_extract_all(marvel_nodes$X_pos,
                                                 "-?\\d+\\.\\d+") %>% 
                                   sapply(`[`, 2))

# we don't need the X_pos anymore
marvel_nodes$X_pos <- NULL
```

Renaming the columns and starting the index column from 1 

```{r}
marvel_nodes <- marvel_nodes |> 
  rename(id = X..index,
         character_name = name) |> 
  mutate(id = id + 1) # for best indexing practice
```


```{r}
marvel_nodes <- marvel_nodes |> 
  mutate(character_name = str_replace_all(character_name, "/", " ")) |> 
  mutate(character_name = str_trim(str_replace(character_name, "^(\\w+),\\s*([\\w\\s]+)$", "\\2 \\1"))) |> 
  mutate(character_name = str_replace_all(character_name, "[^[:alnum:]\\s]", ""))
```


Applying the same indexing logic to 'marvel_links' where character co-appearances are stored.

```{r}
marvel_links <- marvel_links |> 
  rename(source = X..source,
         target = target)

marvel_links <- marvel_links |> 
  mutate(source = source + 1,
         target = target + 1)
```


**Visualization**

```{r}
network_graph <- graph_from_data_frame(d = marvel_links, vertices = marvel_nodes, directed = FALSE)

layout <- as.matrix(marvel_nodes[, c("x_cor", "y_cor")])
plot(network_graph, 
     vertex.label = NA, 
     vertex.size = 2, 
     vertex.color = "red", 
     edge.color = "black", 
     edge.width = 0.5, 
     layout = layout)

V(network_graph)$id <- marvel_nodes$id  # explicitly set id attribute

```


**3. Link Prediction Project**
  
### 3.1.
  
**Delete a fraction of real edges: Randomly remove 10-20% of edges using delete_edges() in igraph. Create a table of deleted (positive) and non-existing (negative) links with sample() for negative class.**
  
  
The below code visualizes the process of preparing data for link prediction on the Marvel network in three steps: first, it plots the original network with all connections; then, it removes 15% of the edges, highlights them in gray, and plots this modified network; finally, it creates a reduced network by deleting those edges, generates a negative class of non-existing links, and plots the reduced network. The positive class consists of the removed edges, while the negative class includes an equal number of randomly sampled non-existing node pairs. The plots use node positions from x_cor and y_cor, with red nodes, black edges, and no labels for clarity.



**Original Network:** The full Marvel network (network_graph) with all its nodes and edges as loaded from your data, showing all connections between characters.

**Network with Removed Edges:** The same network_graph but with 15% of its edges marked in gray to indicate which ones will be removed, while still displaying all nodes and edges.

**Reduced Network:** The modified network (graph_reduced) after actually removing those 15% of edges, showing only the remaining connections between nodes.


```{r}
set.seed(123)
par(mar=c(0,0,0,0), mfrow=c(1,3))
layout <- as.matrix(marvel_nodes[, c("x_cor", "y_cor")])
plot(network_graph, vertex.label=NA, vertex.size=2, vertex.color="red", edge.color="black", edge.width=0.5, layout=layout)

# deleting 15% of edges
edges <- as_data_frame(network_graph, what = "edges")
remove_frac <- 0.15
remove_edges <- sample(1:ecount(network_graph), size = round(remove_frac * ecount(network_graph)))
positive_class <- edges[remove_edges, c("from", "to")]
E(network_graph)$color <- "black"
E(network_graph)$color[remove_edges] <- "gray"
plot(network_graph, vertex.label=NA, vertex.size=2, vertex.color="red", edge.width=0.5, layout=layout)

# creating a negative class and plot reduced graph

graph_reduced <- delete_edges(network_graph, remove_edges)
sample_non_edges <- function(gr, n) {
  non_edges <- data.frame(from = integer(), to = integer())
  while (nrow(non_edges) < n) {
    v1 <- sample(vcount(gr), 1)
    v2 <- sample(vcount(gr), 1)
    if (v1 != v2 && !are_adjacent(gr, v1, v2)) {
      non_edges <- rbind(non_edges, data.frame(from = v1, to = v2))
    }
  }
  non_edges
}
negative_class <- sample_non_edges(graph_reduced, nrow(positive_class))
E(graph_reduced)$color <- "black"
plot(graph_reduced, vertex.label=NA, vertex.size=2, vertex.color="red", edge.width=0.5, layout=layout)

```


### 3.2.

Generate proximity/similarity metrics: Compute heuristics (common neighbors, Jaccard, Adamic-Adar) for all links using similarity() functions in igraph or custom calculations.

**Common Neighbours** 
  
The common neighbours method counts the number of shared neighbors between two nodes, indicating similarity through mutual connections.

In Step 2, we compute similarity matrices on the reduced graph to get similarity scores for all pairs of nodes at once, which is faster than calculating them one-by-one for each link in metrics. 

We use the reduced graph because it reflects the network after removing some edges (positive class), mimicking a realworld scenario where we predict missing links based on the remaining structure.


The dice method in similarity calculates the Dice coefficient for all pairs of nodes, which is a similarity score based on shared neighbors. We use it because it’s a quick way to get a value related to common neighbors, which we can then adjust to find the actual count of shared neighbors.

In the fourth step, we calculate common neighbors by "undoing" the Dice normalization, we take the Dice coefficient from dice_mat and multiply it by (degree(u) + degree(v)) / 2 to convert it back to the raw number of shared neighbors.


```{r}
# making sure our positive/negative classes are integers
positive_class <- positive_class %>%
  mutate(from = as.integer(from),
         to   = as.integer(to))

negative_class <- negative_class %>%
  mutate(from = as.integer(from),
         to   = as.integer(to))


# precomputing ALL three similarity matrices on the reduced graph

dice_mat    <- similarity(graph_reduced, method = "dice")
jaccard_mat <- similarity(graph_reduced, method = "jaccard")
aa_mat      <- similarity(graph_reduced, method = "invlogweighted")

# combining all
metrics <- bind_rows(
  mutate(positive_class, class = 1),
  mutate(negative_class, class = 0)
)    


# for the common neighbours 
metrics$common_neighbors <- mapply(function(u, v) {
  dice_mat[u, v] * (degree(graph_reduced, u) + degree(graph_reduced, v)) / 2
}, metrics$from, metrics$to)


```

**Jaccard**
  
The Jaccard method measures similarity as the ratio of shared neighbors to total unique neighbors of two nodes, normalizing for network size. Let's calculate that too:

```{r}
metrics$jaccard <- mapply(function(u, v) {
  jaccard_mat[u, v]
}, metrics$from, metrics$to)
```


**Adamic-Adar**
  
The Adamic-Adar method weights shared neighbors by the inverse log of their degrees, emphasizing connections through less-connected nodes. Onto calculating that:

```{r}
metrics$adamic_adar <- mapply(function(u, v) {
  aa_mat[u, v]
}, metrics$from, metrics$to)

```


**For the results**
  
  The results from metrics highlight pairs of nodes with at least one common neighbor, all in the negative class (class = 0), meaning they are non-existing links in our Marvel network. 

The common_neighbors column (1 to 3) shows these pairs share a few neighbors despite not being directly connected. 
The jaccard scores (0.04 to 0.67) measure the fraction of shared neighbors relative to all unique neighbors of the pair, where higher values (0.67) indicate the pair’s neighbors are very similar, and lower values (0.04) mean they share little overlap compared to their total connections. 

The adamic_adar scores (0.14 to 0.52) weigh shared neighbors by the inverse log of their degrees, giving more importance to neighbors with fewer connections—higher scores (0.52) suggest the shared neighbors are less connected overall, making them more significant for linking the pair. 

The variation in similarity metrics will help later the classifier identify which pairs are more likely to form connections based on their network proximity.


```{r}

nonzero <- which(metrics$common_neighbors > 0)
head(metrics[nonzero, ], 10)

```


**Preferential Attachment**
  
'Preferential Attachment' is a metric that predicts if two nodes might connect by multiplying the number of connections (degrees) each node has—a higher number means they’re more likely to connect because nodes with more connections tend to form new ones more easily.


The output shows pairs of nodes, all in the positive class (class = 1, meaning these are removed edges that originally existed in our Marvel network). The pref_attach values range from 25 to 4494: low values like 25 (row 5) indicate the nodes have few connections (5 * 5 = 25), suggesting lower likelihood of connecting based on popularity; high values like 4494 (row 6) indicate both nodes have many connections (66 * 68 = 4494), suggesting a higher likelihood of connecting due to their prominence in the network.


```{r}
# preferential attachment (product of degrees)
metrics$pref_attach <- mapply(function(u, v) {
  from_idx <- which(V(network_graph)$id == u)
  to_idx <- which(V(network_graph)$id == v)
  if (length(from_idx) == 0 || length(to_idx) == 0) return(0)
  degree(network_graph, from_idx) * degree(network_graph, to_idx)
}, metrics$from, metrics$to)

# Check results for preferential attachment
head(metrics %>% select(-common_neighbors, -jaccard, -adamic_adar))
```


**3.3.**
  
  Train a binary classifier: Use caret or randomForest in R to train a classifier (logistic regression, random forest) on heuristics with cross-validation (trainControl for k-fold CV).

```{r}


```


**3.4.**
  
  Evaluate model precision: Assess model using confusionMatrix() in caret to calculate precision, recall, and AUC. Identify key heuristic via feature importance (varImp()).

```{r}

```


**3.5.**
  
  Comment on improvements: Suggest incorporating node attributes or advanced algorithms (e.g., graph neural networks) to enhance prediction accuracy.


```{r}

```


